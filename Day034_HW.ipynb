{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8CoX4R7VoCd"
   },
   "source": [
    "# 反爬：代理伺服器/IP\n",
    "\n",
    "* 了解「IP 黑/白名單」的反爬蟲機制\n",
    "* 「IP 黑/白名單」反爬蟲的因應策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-3DZ_r5VoCe"
   },
   "source": [
    "## 作業目標\n",
    "\n",
    "* 目前程式中的 proxy_ips 是手動輸入的，請根據 https://free-proxy-list.net/ 寫一個可自動化抓取可用 Proxy 的 proxy_ips。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iny-9heBVoCf"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-38eec9cb46e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'table'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'proxylisttable'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mtbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tbody'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtbody\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "proxy_ips = []\n",
    "\n",
    "proxy_url = 'https://free-proxy-list.net/'\n",
    "browser = webdriver.Chrome('./chromedriver')\n",
    "browser.get(proxy_url)  # 打開瀏覽器並連到網頁\n",
    "time.sleep(2)  # delay一段時間等待網頁更新完成\n",
    "\n",
    "while True:\n",
    "    time.sleep(3)  # delay一段時間等待網頁更新完成\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    table = soup.find(name = 'table',attrs = {'id':'proxylisttable'})\n",
    "    tbody = table.find('tbody')\n",
    "    \n",
    "    for tr in tbody:\n",
    "        ip = tr.td.string\n",
    "        port = tr.td.next_sibling.string\n",
    "        proxy_ips.append(ip + ':' + port)\n",
    "\n",
    "    n += 1\n",
    "    print(f'第{n}頁已爬完')\n",
    "\n",
    "    for i in range(1):\n",
    "        browser.find_element_by_xpath(\"//li[@class='fg-button ui-button ui-state-default next']/a\").click()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75dIsHjiVoCi"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    ip = random.choice(proxy_ips)\n",
    "    print('Use', ip)\n",
    "    try:\n",
    "        resp = requests.get('http://ip.filefab.com/index.php',\n",
    "                        proxies={'http': ip, 'https': ip}, timeout=10)\n",
    "        soup = BeautifulSoup(resp.text, 'html5lib')\n",
    "        print(soup.find('h1', id='ipd').text.strip())\n",
    "    except:\n",
    "        print('Fail')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
